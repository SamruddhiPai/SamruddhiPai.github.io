<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Samruddhi Pai</title>
  
  <meta name="author" content="Samruddhi Pai">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Samruddhi Pai</name>
              </p>
              <p>I am a Deep Learning Engineer at <a href="https://www.thordrive.ai/">Thordrive</a> working in the perception team to build Deep Learning models for interpretating data generated by RGB Cameras, Thermal Cameras and LiDARs by using Object Detection, Semantic Segmentation and Auto-Calibration Techniques. 
		 
		      I graduated from <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, with a degree in Electrical and Computer Engineering, Advanced program, in December 2022. Being intrigued by Artificial Intelligence's influence on all the sectors, I focused on Machine Learning and Computer Vision during my Masters. I also had an opportunity of working with <a href="https://www.cylab.cmu.edu/directory/bios/bauer-lujo.html">Prof. Lujo Bauer</a> at <a href="https://www.cylab.cmu.edu/">CyLab</a>, the Cyber Security Lab where I worked on Adversarial Training for antivirus models.
              </p>
              <p>
                I worked as project research assistant at Indian Institute of Technology, Bombay on building an automatic timetable scheduling system for Indian Railways. I gained FinTech knowledge during my internship as a Quant Research Associate at Quantify Capital, a quantitative trading firm. During my Bachelor's degree, I had a privilege of leading the Robotics team of my college and got a chance of building autonomous robots for performing complex tasks designed by ABU RoboCon.
              </p>
              <p style="text-align:center">
                <a href="mailto:samruddhipai98@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://drive.google.com/file/d/1riOUp2yFCXyJ7mWZHXOdA9z6YEw7Ghak/view?usp=share_link">Resume</a> &nbsp/&nbsp

                <a href="https://github.com/SamruddhiPai">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="./assets/images/2015ABPS0821P.jpg"><img style="width:100%;max-width:100%;border-radius: 50%;" alt="profile photo" src="./images/my_pic.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Domain of Interest</heading>
              <p>
                I'm interested in computer vision, deep learning, optimization, and data science. Most of my experience and projects have been on Deep Learning's application in vision and security. Being an analytical thinker, I also had opportunities for performing large scale data analysis for the underlying products and giving suggestions to increase the business profitability. Every new problem statement in this domains comes with a whole new set of challenges and this excitement keeps me going on to explore more and more .... 
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='original_image'><img src="images/test6.bmp"  width="160" height='160'>
                <!-- <source type="video/mp4">
                Your browser does not support the video tag. -->
                </div>
                <img src='./images/test6_out.bmp' width="160" height="160">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://dreamfusion3d.github.io/"> -->
                <papertitle>Xeon Canny Edge Detection Acceleration</papertitle>
              </a>
              <!-- <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
							<a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
              <br>
              <a href="https://drive.google.com/file/d/1RRz1MHKsjj4lVuJYdswDjGrQyqdQApXv/view?usp=share_link">project report</a>
              <p></p>
              <p>
                This project is a SIMD implementation of Canny Edge Detector. I worked on accelerating the Sobel Edge Detection and gradient calculation step by analysis the hardware architecture to maximize the throughtput.
              </p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='./images/log1.gif' width="160" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://dreamfusion3d.github.io/"> -->
                <papertitle>Particle Filter</papertitle>
              </a>
              <!-- <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
							<a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
              <p></p>
              <p>
                I implemented particle filter from scratch in Python on real world data collected by traversing a robot in Wean Hall of Carnegie Mellon University.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dreamfusion_image'><video  width=160 height=160 muted autoplay loop>
                <source src="./images/depthMap.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <!-- <img src='./assets/images/tetrahedron_gif.gif' width="160" height="160">
                <img src='./images/depthMap.mp4' width="160" height="160"> -->
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://dreamfusion3d.github.io/"> -->
                <papertitle>DepthMap Generation from Monocular Images</papertitle>
              </a>
              <!-- <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
							<a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              / -->
              <br>
              <a href="https://drive.google.com/file/d/1a63kn4B7yW9hQlgoc9IyVJtBn9px3iTo/view?usp=share_link">Project Report</a> 
              <p></p>
              <p>
                With an aim of eliminating the use of expensive LiDARs for 3D perception, in this project, I along with my teammates generated a depth map from monocular images using deep learning model (PackNet-SfM and MiDAS). Frustums were extracted from this depth map by frustum convnet model to build 3D bounding boxes.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dreamfusion_image'>
                  <img src='./images/pers1_annot.png' width="160" height="160"> 
                </div>
                <img src='./images/result1.png' width="160" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://dreamfusion3d.github.io/"> -->
                <papertitle>Planar Homography from Point Correspondences</papertitle>
              </a>
              <!-- <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
							<a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
              <p></p>
              <p>
                Estimated homographies between two images and transformed one image with respect to the calculated homograpies to lay on top of the other.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dreamfusion_image'>
                  <img src='./images/surface_bunny.jpeg' width="160" height="160"> 
                </div>
                <img src='./images/cmuOnCuboid.jpeg' width="160" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://dreamfusion3d.github.io/"> -->
                <papertitle>Single View Reconstruction</papertitle>
              </a>
              <!-- <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
							<a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
              <p></p>
              <p>
                Using 2D-3D correspondences, transformed points from one dimension to another.
              </p>
            </td>
          </tr>
		  
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Thank you to <a href="https://jonbarron.info/">Jon Barron</a> for the website template!
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
